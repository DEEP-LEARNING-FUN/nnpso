# nnpso
Training of Neural Network using Particle Swarm Optimization.

- Losses: [8.012271, 8.002567, 8.042032, 8.00327] Iteration: 0
- Losses: [6.176217, 4.361371, 8.0, 4.4884667] Iteration: 10000
- Losses: [1.7860475, 1.6976731, 4.1016097, 1.7039604] Iteration: 20000
- Losses: [1.6730804, 1.6676208, 1.702151, 1.6678984] Iteration: 30000
- Losses: [0.2826424, 1.6667058, 1.6677036, 1.0983028] Iteration: 40000
- Losses: [0.10317229, 1.6666698, 1.6667093, 0.16274434] Iteration: 50000
- Losses: [0.038965203, 1.6666677, 1.6666709, 0.062464874] Iteration: 60000
- Losses: [0.01462996, 1.6666673, 1.6666676, 0.023709508] Iteration: 70000
- Losses: [0.0054597864, 1.6666669, 1.6666669, 0.008893641] Iteration: 80000
- Losses: [0.002021174, 1.666667, 1.6666667, 0.003305968] Iteration: 90000

With Regular Neural Networks you just hope that you hadn't chosen the second network. If 20000 iterations took 20 days. Even after 20 days are you really sure that you got the best optimum loss and would further training help. Enter ParticleFlow (Please Play Grand Red Carpet Welcome Music). Built on top of Tensorflow, Particle Flow does much more.

